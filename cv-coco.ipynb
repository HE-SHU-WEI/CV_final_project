{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":6019472,"sourceType":"datasetVersion","datasetId":3445072}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install pycocotools\nfrom torchvision import transforms\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision.models import resnet50\nfrom PIL import Image\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport os\nfrom pycocotools.coco import COCO","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\nimport os\nimport random\nfrom pycocotools.coco import COCO\nimport shutil\n\n\ntrain_annotations_path = '/kaggle/input/coco-image-caption/annotations_trainval2014/annotations/instances_train2014.json'\ntrain_images_path = '/kaggle/input/coco-image-caption/train2014/train2014/'\ntest_annotations_path = '/kaggle/input/coco-image-caption/annotations_trainval2017/annotations/instances_val2017.json'\ntest_images_path = '/kaggle/input/coco-image-caption/val2017/val2017/'\n\n\noutput_dir = '/kaggle/working/coco_face_nonface_dataset'\nos.makedirs(output_dir, exist_ok=True)\nos.makedirs(os.path.join(output_dir, 'train/human_faces'), exist_ok=True)\nos.makedirs(os.path.join(output_dir, 'train/non_faces'), exist_ok=True)\nos.makedirs(os.path.join(output_dir, 'test/human_faces'), exist_ok=True)\nos.makedirs(os.path.join(output_dir, 'test/non_faces'), exist_ok=True)\n\n\n\n\n\ntrain_coco = COCO(train_annotations_path)\ntest_coco = COCO(test_annotations_path)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n\n\ndef filter_images_with_annotations(coco_instance, category_id, min_area=500):\n    annotations = coco_instance.loadAnns(coco_instance.getAnnIds(catIds=category_id))\n    filtered_image_ids = set(\n        ann['image_id']\n        for ann in annotations\n        if 'bbox' in ann and ann['area'] > min_area\n    )\n    return list(filtered_image_ids)\n\n\ndef filter_images_exclude_category(coco_instance, include_category_ids, exclude_category_ids, min_area=500):\n\n    include_annotations = coco_instance.loadAnns(coco_instance.getAnnIds(catIds=include_category_ids))\n    include_image_ids = set(\n        ann['image_id']\n        for ann in include_annotations\n        if 'bbox' in ann and ann['area'] > min_area\n    )\n    \n\n    exclude_annotations = coco_instance.loadAnns(coco_instance.getAnnIds(catIds=exclude_category_ids))\n    exclude_image_ids = set(ann['image_id'] for ann in exclude_annotations)\n\n\n    filtered_image_ids = include_image_ids - exclude_image_ids\n    return list(filtered_image_ids)\n\n\n\n# ----------------------------------\n\n\nface_train_image_ids = filter_images_with_annotations(train_coco, category_id=1, min_area=500)\nface_test_image_ids = filter_images_with_annotations(test_coco, category_id=1, min_area=500)\n\n\nface_train_image_ids = random.sample(face_train_image_ids, min(8000, len(face_train_image_ids)))\nface_test_image_ids = random.sample(face_test_image_ids, min(800, len(face_test_image_ids)))\n\n\nnon_face_category_ids = list(range(16, 26))\nnon_face_train_image_ids = []\nnon_face_test_image_ids = []\n\nfor category_id in non_face_category_ids:\n    non_face_train_image_ids.extend(filter_images_exclude_category(\n        train_coco, include_category_ids=[category_id], exclude_category_ids=[1], min_area=500\n    ))\n    non_face_test_image_ids.extend(filter_images_exclude_category(\n        test_coco, include_category_ids=[category_id], exclude_category_ids=[1], min_area=500\n    ))\n\n\nnon_face_train_image_ids = random.sample(list(set(non_face_train_image_ids)), min(2000, len(non_face_train_image_ids)))\nnon_face_test_image_ids = random.sample(list(set(non_face_test_image_ids)), min(200, len(non_face_test_image_ids)))\n\n\ndef copy_images(image_ids, source_dir, target_dir, coco_instance):\n    for img_id in image_ids:\n        img_info = coco_instance.loadImgs([img_id])[0]\n        img_path = os.path.join(source_dir, img_info['file_name'])\n        if os.path.exists(img_path):\n            shutil.copy(img_path, target_dir)\n\n\ncopy_images(face_train_image_ids, train_images_path, os.path.join(output_dir, 'train/human_faces'), train_coco)\ncopy_images(face_test_image_ids, test_images_path, os.path.join(output_dir, 'test/human_faces'), test_coco)\n\n\ncopy_images(non_face_train_image_ids, train_images_path, os.path.join(output_dir, 'train/non_faces'), train_coco)\ncopy_images(non_face_test_image_ids, test_images_path, os.path.join(output_dir, 'test/non_faces'), test_coco)\n\n\ntrain_human_faces_count = len(os.listdir(os.path.join(output_dir, 'train/human_faces')))\ntrain_non_faces_count = len(os.listdir(os.path.join(output_dir, 'train/non_faces')))\ntest_human_faces_count = len(os.listdir(os.path.join(output_dir, 'test/human_faces')))\ntest_non_faces_count = len(os.listdir(os.path.join(output_dir, 'test/non_faces')))\n\nprint(f\"Train Human Faces: {train_human_faces_count}\")\nprint(f\"Train Non-Faces: {train_non_faces_count}\")\nprint(f\"Test Human Faces: {test_human_faces_count}\")\nprint(f\"Test Non-Faces: {test_non_faces_count}\")\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 檢查資料內容","metadata":{}},{"cell_type":"code","source":"# categories = train_coco.loadCats(train_coco.getCatIds())\n# for cat in categories:\n#     print(f\"ID: {cat['id']}, Name: {cat['name']}\")\n# # ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# from pycocotools.coco import COCO\n# import matplotlib.pyplot as plt\n# import os\n# from PIL import Image\n\n\n# annotations_path = '/kaggle/input/coco-image-caption/annotations_trainval2014/annotations/instances_train2014.json'\n# images_path = '/kaggle/input/coco-image-caption/train2014/train2014/'\n\n\n# coco = COCO(annotations_path)\n\n\n# person_category_id = 1\n# person_image_ids = coco.getImgIds(catIds=person_category_id)\n\n\n# import random\n# selected_image_ids = random.sample(person_image_ids, 5)\n\n\n# def show_coco_images(image_ids, coco, images_path):\n#     plt.figure(figsize=(15, 10))\n#     for i, img_id in enumerate(image_ids):\n#         img_info = coco.loadImgs(img_id)[0]\n#         img_path = os.path.join(images_path, img_info['file_name'])\n        \n#        \n#         image = Image.open(img_path)\n        \n#        \n#         plt.subplot(1, len(image_ids), i + 1)\n#         plt.imshow(image)\n#         plt.axis('off')\n#         plt.title(f\"Image ID: {img_info['id']}\")\n#     plt.tight_layout()\n#     plt.show()\n\n\n# show_coco_images(selected_image_ids, coco, images_path)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport random\nfrom PIL import Image\n\n\ntrain_human_faces_dir = os.path.join(output_dir, 'train/human_faces')\ntrain_non_faces_dir = os.path.join(output_dir, 'train/non_faces')\n\n\ndef get_random_images(dir_path, num_images=5):\n    images = os.listdir(dir_path)\n    selected_images = random.sample(images, num_images)\n    return [os.path.join(dir_path, img) for img in selected_images]\n\n\nhuman_face_images = get_random_images(train_human_faces_dir, num_images=5)\nnon_face_images = get_random_images(train_non_faces_dir, num_images=5)\n\n\ndef display_images_in_row(images, label):\n    num_images = len(images)\n    plt.figure(figsize=(15, 5))  \n    for i, img_path in enumerate(images):\n        img = Image.open(img_path)\n        plt.subplot(1, num_images, i + 1)  \n        plt.imshow(img)\n        plt.axis('off')\n        plt.title(label)\n    plt.tight_layout()\n    plt.show()\n\n\nhuman_face_images = get_random_images(train_human_faces_dir, num_images=5)\nnon_face_images = get_random_images(train_non_faces_dir, num_images=5)\n\n\ndisplay_images_in_row(human_face_images, label=\"Human\")\n\ndisplay_images_in_row(non_face_images, label=\"Non-Human\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\noutput_dir = '/kaggle/working/coco_face_nonface_dataset'\n\ntrain_human_faces_dir = os.path.join(output_dir, 'train/human_faces')\ntrain_non_faces_dir = os.path.join(output_dir, 'train/non_faces')\ntest_human_faces_dir = os.path.join(output_dir, 'test/human_faces')\ntest_non_faces_dir = os.path.join(output_dir, 'test/non_faces')\n\n\ndef create_dataset(image_dir, label):\n    image_files = os.listdir(image_dir)\n    data = [{'file_path': os.path.join(image_dir, img), 'label': label} for img in image_files]\n    return data\n\n\ntrain_data = create_dataset(train_human_faces_dir, label=1) + create_dataset(train_non_faces_dir, label=0)\n\n\ntest_data = create_dataset(test_human_faces_dir, label=1) + create_dataset(test_non_faces_dir, label=0)\n\n\ntrain_df = pd.DataFrame(train_data)\ntest_df = pd.DataFrame(test_data)\n\n\ntrain_df = train_df.sample(frac=1).reset_index(drop=True)\ntest_df = test_df.sample(frac=1).reset_index(drop=True)\n\n\ntrain_csv_path = os.path.join(output_dir, 'train_dataset.csv')\ntest_csv_path = os.path.join(output_dir, 'test_dataset.csv')\ntrain_df.to_csv(train_csv_path, index=False)\ntest_df.to_csv(test_csv_path, index=False)\n\n\nprint(f\"訓練資料集儲存於: {train_csv_path}, 總數: {len(train_df)}\")\nprint(f\"測試資料集儲存於: {test_csv_path}, 總數: {len(test_df)}\")\n\n\nprint(\"\\n訓練資料集部分資料:\")\nprint(train_df.head())\n\nprint(\"\\n測試資料集部分資料:\")\nprint(test_df.head())\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"(train_df.label ==0 ).sum()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torchvision import datasets, transforms, models\nfrom torch.utils.data import DataLoader, Dataset\nimport pandas as pd\nfrom PIL import Image\nimport os\n\n\noutput_dir = '/kaggle/working/coco_face_nonface_dataset'\n\nbatch_size = 32\nnum_epochs = 40\nlearning_rate = 0.001\n\n\ntransform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n])\n\n\nclass CustomDataset(Dataset):\n    def __init__(self, csv_file, transform=None):\n        self.data = pd.read_csv(csv_file)\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        img_path = self.data.iloc[idx, 0]\n        label = self.data.iloc[idx, 1]\n        image = Image.open(img_path).convert(\"RGB\")\n        if self.transform:\n            image = self.transform(image)\n        return image, torch.tensor(label, dtype=torch.long)\n\n\ntrain_csv = os.path.join(output_dir, 'train_dataset.csv')\ntest_csv = os.path.join(output_dir, 'test_dataset.csv')\n\ntrain_dataset = CustomDataset(train_csv, transform=transform)\ntest_dataset = CustomDataset(test_csv, transform=transform)\n\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = models.resnet50(pretrained=True)\n# model = models.resnet34(pretrained=True)\nmodel.fc = nn.Linear(model.fc.in_features, 2)  # 2 類別輸出\nmodel = model.to(device)\n\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=learning_rate)\n\n\ndef train_model(model, train_loader, criterion, optimizer, num_epochs):\n    model.train()\n    for epoch in range(num_epochs):\n        running_loss = 0.0\n        correct = 0\n        total = 0\n        for images, labels in train_loader:\n            images, labels = images.to(device), labels.to(device)\n            \n            \n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            \n            \n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n            \n          \n            running_loss += loss.item()\n            _, predicted = outputs.max(1)\n            total += labels.size(0)\n            correct += predicted.eq(labels).sum().item()\n        \n        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}, Accuracy: {100*correct/total:.2f}%\")\n    print(\"訓練完成！\")\n\n\ndef train_model(model, train_loader, criterion, optimizer, num_epochs):\n    model.train()\n    train_loss_history = []\n    train_acc_history = []\n\n    for epoch in range(num_epochs):\n        running_loss = 0.0\n        correct = 0\n        total = 0\n\n        for images, labels in train_loader:\n            images, labels = images.to(device), labels.to(device)\n            \n   \n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            \n     \n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n            \n\n            running_loss += loss.item()\n            _, predicted = outputs.max(1)\n            total += labels.size(0)\n            correct += predicted.eq(labels).sum().item()\n        \n        epoch_loss = running_loss / len(train_loader)\n        epoch_acc = 100 * correct / total\n        train_loss_history.append(epoch_loss)\n        train_acc_history.append(epoch_acc)\n\n        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.2f}%\")\n    \n    return train_loss_history, train_acc_history\n\n\ndef evaluate_model(model, test_loader):\n    model.eval()\n    correct = 0\n    total = 0\n    with torch.no_grad():\n        for images, labels in test_loader:\n            images, labels = images.to(device), labels.to(device)\n            outputs = model(images)\n            _, predicted = outputs.max(1)\n            total += labels.size(0)\n            correct += predicted.eq(labels).sum().item()\n    accuracy = 100 * correct / total\n    print(f\"測試準確率: {accuracy:.2f}%\")\n    return accuracy\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\ntrain_loss_history, train_acc_history = train_model(model, train_loader, criterion, optimizer, num_epochs)\n\n\ntest_accuracy = evaluate_model(model, test_loader)\n\n\nmodel_save_path = os.path.join(output_dir, 'resnet50_face_classifier.pth')\ntorch.save(model.state_dict(), model_save_path)\nprint(f\"模型已儲存至: {model_save_path}\")\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\nplt.figure(figsize=(12, 5))\n\n\nplt.subplot(1, 2, 1)\nplt.plot(range(1, num_epochs+1), train_loss_history, label='Training Loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.title('Training Loss Curve')\nplt.legend()\n\n\nplt.subplot(1, 2, 2)\nplt.plot(range(1, num_epochs+1), train_acc_history, label='Training Accuracy')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy (%)')\nplt.title('Training Accuracy Curve')\nplt.legend()\n\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nfrom torchvision import transforms\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nimport random\n\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = models.resnet50(pretrained=False)  # 不需要預訓練權重，因為我們要載入自己的權重\nmodel.fc = nn.Linear(model.fc.in_features, 2)  # 2類輸出\nmodel = model.to(device)\n\n\nmodel_save_path = os.path.join(output_dir, 'resnet50_face_classifier.pth')\nmodel.load_state_dict(torch.load(model_save_path, map_location=device))\nmodel.eval()\n\n\ntransform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n])\n\n\ntest_images_dir = os.path.join(output_dir, 'test')\nhuman_faces_dir = os.path.join(test_images_dir, 'human_faces')\nnon_faces_dir = os.path.join(test_images_dir, 'non_faces')\n\n\ndef get_random_test_images(num_images=5):\n    human_faces = [os.path.join(human_faces_dir, f) for f in os.listdir(human_faces_dir)]\n    non_faces = [os.path.join(non_faces_dir, f) for f in os.listdir(non_faces_dir)]\n    selected_images = random.sample(human_faces, num_images // 2) + random.sample(non_faces, num_images // 2)\n    random.shuffle(selected_images)  \n    return selected_images\n\n\ndef predict_image(model, image_path, transform):\n    image = Image.open(image_path).convert(\"RGB\")\n    input_tensor = transform(image).unsqueeze(0).to(device)  # 加入 batch 維度\n    with torch.no_grad():\n        output = model(input_tensor)\n        _, predicted = torch.max(output, 1)\n    label = predicted.item()\n    return label\n\n\ndef display_predictions(model, image_paths, transform):\n    plt.figure(figsize=(12, 8))\n    for i, image_path in enumerate(image_paths):\n        label = predict_image(model, image_path, transform)\n        true_label = \"Human\" if \"human_faces\" in image_path else \"Non-Human\"\n        predicted_label = \"Human\" if label == 1 else \"Non-Human\"\n\n\n        image = Image.open(image_path)\n        plt.subplot(2, len(image_paths) // 2, i + 1)\n        plt.imshow(image)\n        plt.axis('off')\n        plt.title(f\"True: {true_label}\\nPredicted: {predicted_label}\")\n    plt.tight_layout()\n    plt.show()\n\n\ntest_images = get_random_test_images(num_images=6) \ndisplay_predictions(model, test_images, transform)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}